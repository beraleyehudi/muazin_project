# muazin_project
אסקור:
1. זרימת התוכנית
2. מבנה הקבצים
3. מבנה הקוד
4. אלגוריתמיקה ספציפית

זרימת התוכנית:
קבצי השמע מאוחסנים לוקלית (כרגע אין התייחסות לקונטיינרס)
שירות ראשון מייצר מטא דאטה כולל נתיבי הקבצים ומפיץ בקפקא
שירות שני קורא מקפקא - מבצע חישוב עבור יצירת מזהה יחודי, שולח את המטא דאטה לאלסטיק, ואת קבצי השמע ממיר לבינארי ומעלה למונגו
שירות שלישי קורא ממונגו את הקבצים - מבצע תמלול ומעדכן שדה חדש באלסטיק - באמצעות המזהה היחודי
שירות רביעי קורא מאלסטיק מבצע חישוב הסיכון בטקסט ומוסיף שדות חדשים באלסטיק על פי הדרישות

נקודה לציון: בין כל שירות ושירות הייתי צריך להשתמש בקפקא מלבד בין השירות השלישי לרביעי - כיוון שהשירות הזה מבצע עיבוד ארוך, והפצת התשובות שלו מתרחשת בצורה איטית. הייתי מממש את קפקא לכל שאר השירותים כדי שהטכנולוגיה תעמוד בלחץ המערכת שלי.

מבנה הקבצים:
-app - גןף המערכת
    -connections - רכיבי החיבור לשירותים שונים
        -elasticsearch
        -kafka
        -mongo_db
    -dal - רכיב המחבר בין צרכי המערכת לליבת רכיבי החיבור
        - elastic_dal
        - mongo_dal
    
    -services - שירותי המערכת השונים - השירותים הללו אינם גנריים ונבנו לצורך הספציפי הנוכחי
        - spcific_service
            - configs = הגדרות קבועות עבור השירות הזה, כגון שמות של פרטי התקשרות וכו
            - service = גוף השירות עצמו - מבצע כל מה שצריך לבצע
            - helper = קובץ פונקציות עזר לשירות הנוכחי. על מנת לשמור את השירות נקי ובעל אופי קריא וברור. פירוט בסעיף 

- requirements
- etc..


מבנה הקוד:

עבור ראשית החיבורים לכל שירות חיצוני - יצרתי ליבת חיבור - מחלקות חיבור singleton ליצירת חיבור אחד בלבד לכל שלבי התוכנית. להימנע מבזבוז משאבים בבקשת השירות (למען האמת אינני יודע כתיבת singleton עשיתי משהו דומה)
עבור החיבור בין השירותים של המערכת שלי לשירותים כלליים אלה יש מחלקות ביניים המבינות את צרכי התוכנית ומתקשרות בהתאם מול החיבורים
שירותי המערכת שלי:
השירות עצמו מבצע כל מה שצריך לבצע - עושה זאת בצורה מודולרית ונקייה. מבצע כל פעולה בנפרד - ועבור פעולות שאינן חלק אמיתי מהשירות - משתמש בקובץ העזר שלו.
לדוגמה: שירות סיווג הטקסט - הוא יודע שהוא צריך לחשב את רמת הסיכון של הטקסט, לחלק לשנ=תי צורות סיווג ולשולחן כשדות נוספים לאלסטיק.
השירות עושה זאת רק בלי לדעת כיצד לבצע את החישוב; באיזה אופן לסווג; או אפילו מהוו המאגר עליו מבוסס החישוב וכיצד ממירים את המאגר המוצפן - 
את כל זאת משאיר לhelper שלו. הhelper לרוב יהיה ספציפי עבור התוכנית, אך לעיתים בעל אופי גנרי. תכנון טוב היה גורם לרובו לשבת בתיקיית utils כלשהי.
העיקר הוא: השירות יבצע את השירות שלו שלב אחר שלב רק בצורה נקייה וברורה.


אלגוריתמיקה ספציפית:

1. מזהה יחודי:
חישוב של תאריך הקובץ (עם המרה רלוונטית - לא מעניין אותנו, כאמור, כיצד בדיוק מתבצעת ההמרה :) ) * גודלו

2. חישוב סיכון:
ניקוד של 100% מתקבל עבור טקסט שכל מילותיו הן בדיוק המילים מהמאגר המסוכן.
המאגר הפחות מסוכן חותך בחצי את האחוזים
מילים בטקסט שאינן מהמאגר - מורידות את האחוזים
מילים מהמאגר שחוזרות על עצמן (מספר ההופעות משתקלל עם יחודיות ההופעות. מקרה קיצון - כל הטקסט נמצא במאגר - כולו מורכב ממילה אחת מהמאגר שחוזרת על עצמה) - מורידות את האחוזים

היות שמדובר בשקלול שני הפרמטרים האחרונים בשווה (מספר ההופעות תלוי באופן ישיר בכמות המילים השונות) - האחוזים שמתקבלים מוכפלים זה בזה
חישוב אחוז ההופעות - הופעות חלקי גודל הטקסט. (100 הופעות עבור 100000 מילים אינן שוות ל100 הופעות עבור 101 מילים  )
חישוב אחוז הגיוון (כמה מילים שנמצאו שונות זו מזו ) - מילים שונות שנמצאו חלקי גודל מילןות המאגר (נמצאו רק 4 מילים שונות. אך אורך המאגר הוא 4 - ודאי שמדובר ב100% כיסוי המאגר)

3. חישוב סף סיכון:
מחשבה מהו טקסט מסוכן - כמה אחוז מילים מתוך המאגר אמורות להימצא בטקסט על מנת שיהיה. כמה מתוך אמורות להיות המילים שונות - הכפלה של הנתונים הללו אמורה לקבוע את הסף. 
ניתן לאשרר את הסף באמצעות חומר ממשי

(האלגוריתם שבניתי עוד צריך אי אלו שיפורים לעמוד בדרישות הללו )